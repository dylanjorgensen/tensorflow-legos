{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Resources:\n",
    "- [TensorFlow.org - API - NN](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev3 toc-item\"><a href=\"#Resources:\" data-toc-modified-id=\"Resources:-0.0.1\"><span class=\"toc-item-num\">0.0.1&nbsp;&nbsp;</span>Resources:</a></div><div class=\"lev1 toc-item\"><a href=\"#Activation\" data-toc-modified-id=\"Activation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Activation</a></div><div class=\"lev1 toc-item\"><a href=\"#ANN\" data-toc-modified-id=\"ANN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>ANN</a></div><div class=\"lev2 toc-item\"><a href=\"#Regression\" data-toc-modified-id=\"Regression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Regression</a></div><div class=\"lev3 toc-item\"><a href=\"#=-tf.nn.softmax()...\" data-toc-modified-id=\"=-tf.nn.softmax()...-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>= tf.nn.softmax()...</a></div><div class=\"lev3 toc-item\"><a href=\"#tf.tanh\" data-toc-modified-id=\"tf.tanh-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>tf.tanh</a></div><div class=\"lev2 toc-item\"><a href=\"#Classification\" data-toc-modified-id=\"Classification-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Classification</a></div><div class=\"lev3 toc-item\"><a href=\"#=-tf.nn.relu()...\" data-toc-modified-id=\"=-tf.nn.relu()...-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>= tf.nn.relu()...</a></div><div class=\"lev1 toc-item\"><a href=\"#CNNs\" data-toc-modified-id=\"CNNs-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>CNNs</a></div><div class=\"lev2 toc-item\"><a href=\"#Convolution\" data-toc-modified-id=\"Convolution-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Convolution</a></div><div class=\"lev3 toc-item\"><a href=\"#=-tf.nn.conv2d()...\" data-toc-modified-id=\"=-tf.nn.conv2d()...-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>= tf.nn.conv2d()...</a></div><div class=\"lev2 toc-item\"><a href=\"#Pooling\" data-toc-modified-id=\"Pooling-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Pooling</a></div><div class=\"lev3 toc-item\"><a href=\"#=-tf.nn.max_pool()...\" data-toc-modified-id=\"=-tf.nn.max_pool()...-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>= tf.nn.max_pool()...</a></div><div class=\"lev1 toc-item\"><a href=\"#RNNs\" data-toc-modified-id=\"RNNs-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>RNNs</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation\n",
    "- !! IMPORTANT!!! If we don't apply a non-linearity to our model there is **no advantage to adding hidden layers**\n",
    "- A sequence of non-linearitys give the model additional complexity.\n",
    "- We can also squish the linearity in way that gives up classification output.\n",
    "- [TensorFlow API - Activation Functions](https://www.tensorflow.org/versions/r0.10/api_docs/python/nn.html#activation-functions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### = tf.nn.softmax()...\n",
    "- [tf.nn.softmax(logits, dim=-1, name=None)](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8e35187b1b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactivation_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "activation_out = tf.nn.softmax(activity_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax Raw Coded\n",
    "\n",
    "scores = [3.0, 1.0, 0.2]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    # TODO: Compute and return softmax(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "print(softmax(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The probability of the class sums to one, and increases with the score x. \n",
    "%matplotlib inline  \n",
    "# Plot softmax curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-2.0, 6.0, 0.1)\n",
    "print(x)\n",
    "\n",
    "scores = np.vstack([x, np.ones_like(x), 0.2 * np.ones_like(x)])\n",
    "\n",
    "plt.plot(x, softmax(scores).T, linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.tanh\n",
    "- [tf.tanh(x, name=None)](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activation_out = tf.tanh(activity_out, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### = tf.nn.relu()...\n",
    "- [tf.nn.relu(features, name=None)](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#relu)\n",
    "- This is a simple way to get the benifits linear power with a little bit of complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activation_out = tf.nn.relu(activity_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activation_out = tf.nn.relu(tf.nn.xw_plus_b(px, w1, b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs\n",
    "- [Convolution](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#convolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### = tf.nn.conv2d()..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.conv2d_transpose(value, filter, output_shape, strides, padding=SAME, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### = tf.nn.max_pool()..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.max_pool(value, ksize, strides, padding, data_format=NHWC, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.rnn(cell, inputs, initial_state=None, dtype=None, sequence_length=None, scope=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
