{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Log-Parameters\" data-toc-modified-id=\"Log-Parameters-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Log Parameters</a></div><div class=\"lev1 toc-item\"><a href=\"#Classification\" data-toc-modified-id=\"Classification-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Classification</a></div><div class=\"lev3 toc-item\"><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Accuracy</a></div><div class=\"lev3 toc-item\"><a href=\"#Precision-&amp;-Recall\" data-toc-modified-id=\"Precision-&amp;-Recall-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>Precision &amp; Recall</a></div><div class=\"lev3 toc-item\"><a href=\"#F-Score\" data-toc-modified-id=\"F-Score-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>F-Score</a></div><div class=\"lev3 toc-item\"><a href=\"#Confusion-Matrix\" data-toc-modified-id=\"Confusion-Matrix-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>Confusion Matrix</a></div><div class=\"lev1 toc-item\"><a href=\"#Regression\" data-toc-modified-id=\"Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Regression</a></div><div class=\"lev3 toc-item\"><a href=\"#Absolute-Error\" data-toc-modified-id=\"Absolute-Error-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Absolute Error</a></div><div class=\"lev3 toc-item\"><a href=\"#Mean\" data-toc-modified-id=\"Mean-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Mean</a></div><div class=\"lev3 toc-item\"><a href=\"#Mean-Squared-Error\" data-toc-modified-id=\"Mean-Squared-Error-3.0.3\"><span class=\"toc-item-num\">3.0.3&nbsp;&nbsp;</span>Mean Squared Error</a></div><div class=\"lev1 toc-item\"><a href=\"#Neuron-Representations\" data-toc-modified-id=\"Neuron-Representations-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Neuron Representations</a></div><div class=\"lev3 toc-item\"><a href=\"#Visually-Understand-Neuron/Weights\" data-toc-modified-id=\"Visually-Understand-Neuron/Weights-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Visually Understand Neuron/Weights</a></div><div class=\"lev1 toc-item\"><a href=\"#Early-Termination\" data-toc-modified-id=\"Early-Termination-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Early Termination</a></div><div class=\"lev3 toc-item\"><a href=\"#=-Example-2\" data-toc-modified-id=\"=-Example-2-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>= Example 2</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Parameters\n",
    "- Along side any metrics we need our models parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.5\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph\n",
    "\n",
    "# Evaluation: Graph computation (for hot encodings)\n",
    "py_evaluation = tf.argmax(py, 1) # Returns np.array (55000,)\n",
    "y__evaluation = tf.argmax(y_, 1) # Returns np.array (55000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation: variables\n",
    "py_evaluation = sess.run(py_evaluation, feed_dict={px: train_x, py: train_y_hot})\n",
    "y__evaluation = sess.run(y__evaluation, feed_dict={px: train_x, py: train_y_hot})\n",
    "\n",
    "print(type(py_evaluation))\n",
    "print(py_evaluation[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "- Accuracy, precision, recall, and F-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "- Number of items in a class labeled correctly / all items in that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy: Tensorflow\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy: Sk-Learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(py_evaluation, y__evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"Precision:\", precision_score(py_evaluation, y__evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 Score:\", f1_score(py_evaluation, y__evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "- _---__(+)______(-)\n",
    "- (+) | TP | FN\n",
    "- (-) | FP | TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix (Print)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion Matrix:\", confusion_matrix(py_evaluation, y__evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix (Visual)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "num_classes = 10 # For each outcome class\n",
    "cm = confusion_matrix(py_evaluation, y__evaluation)\n",
    "\n",
    "# Plot the confusion matrix as an image.\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "# Make various adjustments to the plot.\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(num_classes)\n",
    "plt.xticks(tick_marks, range(num_classes))\n",
    "plt.yticks(tick_marks, range(num_classes))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "- Mean, absolute error and mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visually Understand Neuron/Weights\n",
    "- The weights can also be plotted in a way where we make positive weights red and negative weights blue. \n",
    "- These weights can be intuitively understood as image-filters.\n",
    "- For example, the weights used to determine if an image shows a zero-digit have a positive reaction (red) to an image of a circle, and have a negative reaction (blue) to images with content in the centre of the circle.\n",
    "- Similarly, the weights used to determine if an image shows a one-digit react positively (red) to a vertical line in the centre of the image, and react negatively (blue) to images with content surrounding that line.\n",
    "- Note that the weights mostly look like the digits they're supposed to recognize. This is because only one optimization iteration has been performed so the weights are only trained on 100 images. After training on several thousand images, the weights become more difficult to interpret because they have to recognize many variations of how digits can be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_size = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the values for the weights from the TensorFlow variable.\n",
    "w = sess.run(W)\n",
    "\n",
    "# Get the lowest and highest values for the weights.\n",
    "# This is used to correct the colour intensity across\n",
    "# the images so they can be compared with each other.\n",
    "w_min = np.min(w)\n",
    "w_max = np.max(w)\n",
    "\n",
    "# Create figure with 3x4 sub-plots,\n",
    "# where the last 2 sub-plots are unused.\n",
    "fig, axes = plt.subplots(3, 4)\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Only use the weights for the first 10 sub-plots.\n",
    "    if i<10:\n",
    "        # Get the weights for the i'th digit and reshape it.\n",
    "        # Note that w.shape == (img_size_flat, 10)\n",
    "        image = w[:, i].reshape((img_shape))\n",
    "\n",
    "        # Set the label for the sub-plot.\n",
    "        ax.set_xlabel(\"Weights: {0}\".format(i))\n",
    "\n",
    "        # Plot the image.\n",
    "        ax.imshow(image, vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "\n",
    "    # Remove ticks from each sub-plot.\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Early Termination\n",
    "- The classification accuracy for the validation-set will be calculated for every 100 iterations of the optimization function below.\n",
    "- The optimization will be stopped if the validation accuracy has not been improved in 1000 iterations.\n",
    "- We need a few variables to keep track of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best validation accuracy seen so far.\n",
    "best_validation_accuracy = 0.0\n",
    "\n",
    "# Iteration-number for last improvement to validation accuracy.\n",
    "last_improvement = 0\n",
    "\n",
    "# Stop optimization if no improvement found in this many iterations.\n",
    "require_improvement = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variables rather than local copies.\n",
    "    global total_iterations\n",
    "    global best_validation_accuracy\n",
    "    global last_improvement\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        # Increase the total number of iterations performed.\n",
    "        # It is easier to update it in each iteration because\n",
    "        # we need this number several times in the following.\n",
    "        total_iterations += 1\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations and after last iteration.\n",
    "        if (total_iterations % 100 == 0) or (i == (num_iterations - 1)):\n",
    "\n",
    "            # Calculate the accuracy on the training-batch.\n",
    "            acc_train = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "            # Calculate the accuracy on the validation-set.\n",
    "            # The function returns 2 values but we only need the first.\n",
    "            acc_validation, _ = validation_accuracy()\n",
    "\n",
    "            # If validation accuracy is an improvement over best-known.\n",
    "            if acc_validation > best_validation_accuracy:\n",
    "                # Update the best-known validation accuracy.\n",
    "                best_validation_accuracy = acc_validation\n",
    "                \n",
    "                # Set the iteration for the last improvement to current.\n",
    "                last_improvement = total_iterations\n",
    "\n",
    "                # Save all variables of the TensorFlow graph to file.\n",
    "                saver.save(sess=session, save_path=save_path)\n",
    "\n",
    "                # A string to be printed below, shows improvement found.\n",
    "                improved_str = '*'\n",
    "            else:\n",
    "                # An empty string to be printed below.\n",
    "                # Shows that no improvement was found.\n",
    "                improved_str = ''\n",
    "            \n",
    "            # Status-message for printing.\n",
    "            msg = \"Iter: {0:>6}, Train-Batch Accuracy: {1:>6.1%}, Validation Acc: {2:>6.1%} {3}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc_train, acc_validation, improved_str))\n",
    "\n",
    "        # If no improvement found in the required number of iterations.\n",
    "        if total_iterations - last_improvement > require_improvement:\n",
    "            print(\"No improvement found in a while, stopping optimization.\")\n",
    "\n",
    "            # Break out from the for-loop.\n",
    "            break\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### = Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://youtu.be/Lx8JUJROkh0?t=4m40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variables rather than local copies.\n",
    "    global total_iterations\n",
    "    global best_validation_accuracy\n",
    "    global last_improvement\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
